# Data Engineering with AWS

Welcome to my Data Engineering with AWS repository! This repo is a 
collection of projects completed as part of the 
Udacity Data Engineering with AWS Nanodegree program.

## Project Overview
The purpose of this repo is to showcase my skills and understanding 
of data engineering using AWS services. Each project focuses on 
different aspects of data engineering, including collecting, 
processing, storing, and visualizing data.

## Project List
- Project 1: Data Modeling with Apache Cassandra - Database and ETL pipeline, in Apache Cassandra, designed to optimize queries for a music startup Sparkify.
- Project 2: Cloud Data Warehouses - built an ELT pipeline that extracts data from S3, stages in Redshift, and transforms into a set of dimensional tables for Sparkify startup analytics team
- Project 3: Data Lake with Spark - an ETL pipeline for a data lake. The data resides in S3, in a directory with JSON files. The task is to load data from S3, process the data into analytics tables using Spark, and load them back into S3 deploying this Spark process on a cluster using AWS.
- Project 4: Automated Pipeleins with Airflow - Configured and scheduled data pipelines with Airflow and monitor and debug production pipelines.

## Technologies Used
The following AWS services were used in these projects:
- Amazon S3
- Amazon Redshift
- AWS Glue
- Appache Cassandra
- Appache Airflow
- PostgreSQL
